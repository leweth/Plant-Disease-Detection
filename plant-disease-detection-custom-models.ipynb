{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plant disease detection using VGG inspired models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T00:45:04.255917Z",
     "iopub.status.busy": "2025-01-10T00:45:04.255622Z",
     "iopub.status.idle": "2025-01-10T00:45:14.157124Z",
     "shell.execute_reply": "2025-01-10T00:45:14.156434Z",
     "shell.execute_reply.started": "2025-01-10T00:45:04.255895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Path to the dataset\n",
    "data_dir = '/kaggle/input/plantvillage-dataset/color'\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load the full dataset without transformations\n",
    "full_dataset = datasets.ImageFolder(\n",
    "    root=data_dir, \n",
    "    transform=data_transforms\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T00:45:14.158373Z",
     "iopub.status.busy": "2025-01-10T00:45:14.158126Z",
     "iopub.status.idle": "2025-01-10T00:45:14.171124Z",
     "shell.execute_reply": "2025-01-10T00:45:14.170061Z",
     "shell.execute_reply.started": "2025-01-10T00:45:14.158341Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 38\n",
      "Class names: ['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_', 'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy', 'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch', 'Strawberry___healthy', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n"
     ]
    }
   ],
   "source": [
    "# Extract image paths and labels\n",
    "image_paths = [sample[0] for sample in full_dataset.samples]\n",
    "labels = [sample[1] for sample in full_dataset.samples]\n",
    "class_names = full_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T00:45:19.211135Z",
     "iopub.status.busy": "2025-01-10T00:45:19.210819Z",
     "iopub.status.idle": "2025-01-10T00:45:19.216178Z",
     "shell.execute_reply": "2025-01-10T00:45:19.215160Z",
     "shell.execute_reply.started": "2025-01-10T00:45:19.211112Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"GPU Available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T00:45:21.690716Z",
     "iopub.status.busy": "2025-01-10T00:45:21.690430Z",
     "iopub.status.idle": "2025-01-10T00:49:01.709755Z",
     "shell.execute_reply": "2025-01-10T00:49:01.708787Z",
     "shell.execute_reply.started": "2025-01-10T00:45:21.690696Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.4664, 0.4891, 0.4104])\n",
      "Std: tensor([0.1761, 0.1500, 0.1925])\n"
     ]
    }
   ],
   "source": [
    "# Create a DataLoader to iterate through the dataset\n",
    "dataloader = DataLoader(full_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Initialize variables to accumulate pixel values\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "total_images = 0\n",
    "\n",
    "# Iterate through the dataset to compute mean and std\n",
    "for images, _ in dataloader:\n",
    "    batch_size = images.size(0)  # Number of images in the current batch\n",
    "    images = images.view(batch_size, images.size(1), -1)  # Flatten height and width dimensions\n",
    "    mean += images.mean(2).sum(0)  # Sum of means for each channel (RGB)\n",
    "    std += images.std(2).sum(0)    # Sum of stds for each channel (RGB)\n",
    "    total_images += batch_size     # Accumulate total number of images\n",
    "\n",
    "# Divide by the total number of images to get the average mean and std\n",
    "mean /= total_images\n",
    "std /= total_images\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T00:50:30.496856Z",
     "iopub.status.busy": "2025-01-10T00:50:30.496542Z",
     "iopub.status.idle": "2025-01-10T00:50:30.501460Z",
     "shell.execute_reply": "2025-01-10T00:50:30.500470Z",
     "shell.execute_reply.started": "2025-01-10T00:50:30.496835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the transformation pipeline\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),          # Resize images to 256x256 pixels\n",
    "    transforms.ToTensor(),                  # Convert images to PyTorch tensors and scale to [0, 1]\n",
    "    transforms.Normalize(mean=mean, std=std)  # Normalize using your dataset's mean and std\n",
    "])\n",
    "\n",
    "# Apply the transformations to the already loaded dataset\n",
    "full_dataset.transform = data_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T01:13:44.948465Z",
     "iopub.status.busy": "2025-01-10T01:13:44.948004Z",
     "iopub.status.idle": "2025-01-10T01:13:45.028253Z",
     "shell.execute_reply": "2025-01-10T01:13:45.027476Z",
     "shell.execute_reply.started": "2025-01-10T01:13:44.948436Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 54305\n",
      "Training samples: 43429\n",
      "Validation samples: 5417\n",
      "Testing samples: 5459\n"
     ]
    }
   ],
   "source": [
    "# Manual stratified splitting\n",
    "# Step 1: Organize indices by class\n",
    "from collections import defaultdict\n",
    "\n",
    "# Transform the list structure of labels to a dictionnary of lists representing keys and \n",
    "# indices representing values\n",
    "class_to_indices = defaultdict(list)\n",
    "for idx, label in enumerate(labels): #idx is the index in the dataset and label is the value at that position\n",
    "    class_to_indices[label].append(idx)\n",
    "\n",
    "# Step 2: Split indices for each class\n",
    "train_indices = []\n",
    "val_indices = []\n",
    "test_indices = []\n",
    "\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "for label, indices in class_to_indices.items():\n",
    "    # Shuffle the indices for this class\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    # Detecting the number of samples in each class\n",
    "    n_total = len(indices)\n",
    "    n_train = int(train_ratio * n_total)\n",
    "    n_val = int(val_ratio * n_total)\n",
    "    n_test = n_total - n_train - n_val  # Ensure all samples are used\n",
    "\n",
    "    # Split the indices\n",
    "    train_idx = indices[:n_train]\n",
    "    val_idx = indices[n_train:n_train + n_val]\n",
    "    test_idx = indices[n_train + n_val:]\n",
    "\n",
    "    # Append to the respective lists the samples of each class after splitting\n",
    "    train_indices.extend(train_idx)\n",
    "    val_indices.extend(val_idx)\n",
    "    test_indices.extend(test_idx)\n",
    "\n",
    "# Shuffle the final indices to ensure randomness across classes\n",
    "random.shuffle(train_indices)\n",
    "random.shuffle(val_indices)\n",
    "random.shuffle(test_indices)\n",
    "\n",
    "print(f\"Total samples: {len(full_dataset)}\")\n",
    "print(f\"Training samples: {len(train_indices)}\")\n",
    "print(f\"Validation samples: {len(val_indices)}\")\n",
    "print(f\"Testing samples: {len(test_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T01:18:42.825757Z",
     "iopub.status.busy": "2025-01-10T01:18:42.825468Z",
     "iopub.status.idle": "2025-01-10T01:18:42.830615Z",
     "shell.execute_reply": "2025-01-10T01:18:42.829657Z",
     "shell.execute_reply.started": "2025-01-10T01:18:42.825731Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "# Create subsets using the indices from the stratified split\n",
    "train_subset = Subset(full_dataset, train_indices)\n",
    "val_subset = Subset(full_dataset, val_indices)\n",
    "test_subset = Subset(full_dataset, test_indices)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_subset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,  # Shuffle for training\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_subset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,  # No shuffle for validation\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_subset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,  # No shuffle for testing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T04:34:29.147126Z",
     "iopub.status.busy": "2025-01-10T04:34:29.146744Z",
     "iopub.status.idle": "2025-01-10T04:34:29.419737Z",
     "shell.execute_reply": "2025-01-10T04:34:29.419018Z",
     "shell.execute_reply.started": "2025-01-10T04:34:29.147101Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = PlantDiseaseCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T04:35:02.265412Z",
     "iopub.status.busy": "2025-01-10T04:35:02.265073Z",
     "iopub.status.idle": "2025-01-10T05:39:21.291540Z",
     "shell.execute_reply": "2025-01-10T05:39:21.290414Z",
     "shell.execute_reply.started": "2025-01-10T04:35:02.265388Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 3.6466, Train Accuracy: 7.84%\n",
      "Validation Loss: 3.6277, Validation Accuracy: 9.88%\n",
      "Epoch 2/10\n",
      "Train Loss: 3.6069, Train Accuracy: 9.79%\n",
      "Validation Loss: 3.5814, Validation Accuracy: 10.15%\n",
      "Epoch 3/10\n",
      "Train Loss: 3.5327, Train Accuracy: 10.02%\n",
      "Validation Loss: 3.4520, Validation Accuracy: 10.15%\n",
      "Epoch 4/10\n",
      "Train Loss: 3.3918, Train Accuracy: 10.00%\n",
      "Validation Loss: 3.3640, Validation Accuracy: 10.15%\n",
      "Epoch 5/10\n",
      "Train Loss: 3.3597, Train Accuracy: 10.07%\n",
      "Validation Loss: 3.3514, Validation Accuracy: 9.88%\n",
      "Epoch 6/10\n",
      "Train Loss: 3.3530, Train Accuracy: 10.05%\n",
      "Validation Loss: 3.3476, Validation Accuracy: 10.15%\n",
      "Epoch 7/10\n",
      "Train Loss: 3.3507, Train Accuracy: 9.76%\n",
      "Validation Loss: 3.3461, Validation Accuracy: 10.15%\n",
      "Epoch 8/10\n",
      "Train Loss: 3.3508, Train Accuracy: 10.07%\n",
      "Validation Loss: 3.3455, Validation Accuracy: 10.15%\n",
      "Epoch 9/10\n",
      "Train Loss: 3.3496, Train Accuracy: 9.87%\n",
      "Validation Loss: 3.3446, Validation Accuracy: 9.88%\n",
      "Epoch 10/10\n",
      "Train Loss: 3.3485, Train Accuracy: 10.06%\n",
      "Validation Loss: 3.3439, Validation Accuracy: 9.88%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)  # Move the model to GPU\n",
    "\n",
    "num_epochs = 10\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# Open a file to save the result\n",
    "with open(\"training_results_momentum.txt\", \"w\") as f:\n",
    "    f.write(\"Epoch\\tTrain Loss\\tTrain Accuracy\\tValidation Loss\\tValidation Accuracy\\n\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            # Move data to GPU\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = 100 * correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_history.append((train_loss, train_accuracy))\n",
    "\n",
    "        # Validation Loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                # Move data to GPU\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "        val_history.append((val_loss, val_accuracy))\n",
    "\n",
    "        # Print metrics to console\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "        # Save metrics to file\n",
    "        f.write(f\"{epoch+1}\\t{train_loss:.4f}\\t{train_accuracy:.2f}\\t{val_loss:.4f}\\t{val_accuracy:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T05:39:21.293345Z",
     "iopub.status.busy": "2025-01-10T05:39:21.293004Z",
     "iopub.status.idle": "2025-01-10T05:39:43.454042Z",
     "shell.execute_reply": "2025-01-10T05:39:43.453050Z",
     "shell.execute_reply.started": "2025-01-10T05:39:21.293312Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.3439, Test Accuracy: 9.88%\n",
      "Precision: 0.0098, Recall: 0.0988, F1-Score: 0.0178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "# Lists to store all predictions and labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        # Move inputs and labels to the same device as the model\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Store predictions and labels for metric calculation\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = 100 * test_correct / test_total\n",
    "test_loss /= len(val_loader)\n",
    "\n",
    "# Precision, Recall, F1-Score\n",
    "precision = precision_score(all_labels, all_preds, average='weighted') \n",
    "recall = recall_score(all_labels, all_preds, average='weighted')      \n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')              \n",
    "\n",
    "# Print metrics\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Save results to a file\n",
    "with open(\"evaluation_results_momentum.txt\", \"w\") as f:\n",
    "    f.write(\"Metric\\tValue\\n\")\n",
    "    f.write(f\"Test Loss\\t{test_loss:.4f}\\n\")\n",
    "    f.write(f\"Test Accuracy\\t{test_accuracy:.2f}%\\n\")\n",
    "    f.write(f\"Precision\\t{precision:.4f}\\n\")\n",
    "    f.write(f\"Recall\\t{recall:.4f}\\n\")\n",
    "    f.write(f\"F1-Score\\t{f1:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T05:39:43.456148Z",
     "iopub.status.busy": "2025-01-10T05:39:43.455775Z",
     "iopub.status.idle": "2025-01-10T05:40:09.964286Z",
     "shell.execute_reply": "2025-01-10T05:40:09.963338Z",
     "shell.execute_reply.started": "2025-01-10T05:39:43.456114Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9.84%\n",
      "\n",
      "Classification Report:\n",
      "                                                    precision    recall  \\\n",
      "Apple___Apple_scab                                   0.000000  0.000000   \n",
      "Apple___Black_rot                                    0.000000  0.000000   \n",
      "Apple___Cedar_apple_rust                             0.000000  0.000000   \n",
      "Apple___healthy                                      0.000000  0.000000   \n",
      "Blueberry___healthy                                  0.000000  0.000000   \n",
      "Cherry_(including_sour)___Powdery_mildew             0.000000  0.000000   \n",
      "Cherry_(including_sour)___healthy                    0.000000  0.000000   \n",
      "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot   0.000000  0.000000   \n",
      "Corn_(maize)___Common_rust_                          0.000000  0.000000   \n",
      "Corn_(maize)___Northern_Leaf_Blight                  0.000000  0.000000   \n",
      "Corn_(maize)___healthy                               0.000000  0.000000   \n",
      "Grape___Black_rot                                    0.000000  0.000000   \n",
      "Grape___Esca_(Black_Measles)                         0.000000  0.000000   \n",
      "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)           0.000000  0.000000   \n",
      "Grape___healthy                                      0.000000  0.000000   \n",
      "Orange___Haunglongbing_(Citrus_greening)             0.000000  0.000000   \n",
      "Peach___Bacterial_spot                               0.000000  0.000000   \n",
      "Peach___healthy                                      0.000000  0.000000   \n",
      "Pepper,_bell___Bacterial_spot                        0.000000  0.000000   \n",
      "Pepper,_bell___healthy                               0.000000  0.000000   \n",
      "Potato___Early_blight                                0.000000  0.000000   \n",
      "Potato___Late_blight                                 0.000000  0.000000   \n",
      "Potato___healthy                                     0.000000  0.000000   \n",
      "Raspberry___healthy                                  0.000000  0.000000   \n",
      "Soybean___healthy                                    0.000000  0.000000   \n",
      "Squash___Powdery_mildew                              0.000000  0.000000   \n",
      "Strawberry___Leaf_scorch                             0.000000  0.000000   \n",
      "Strawberry___healthy                                 0.000000  0.000000   \n",
      "Tomato___Bacterial_spot                              0.000000  0.000000   \n",
      "Tomato___Early_blight                                0.000000  0.000000   \n",
      "Tomato___Late_blight                                 0.000000  0.000000   \n",
      "Tomato___Leaf_Mold                                   0.000000  0.000000   \n",
      "Tomato___Septoria_leaf_spot                          0.000000  0.000000   \n",
      "Tomato___Spider_mites Two-spotted_spider_mite        0.000000  0.000000   \n",
      "Tomato___Target_Spot                                 0.000000  0.000000   \n",
      "Tomato___Tomato_Yellow_Leaf_Curl_Virus               0.098370  1.000000   \n",
      "Tomato___Tomato_mosaic_virus                         0.000000  0.000000   \n",
      "Tomato___healthy                                     0.000000  0.000000   \n",
      "accuracy                                             0.098370  0.098370   \n",
      "macro avg                                            0.002589  0.026316   \n",
      "weighted avg                                         0.009677  0.098370   \n",
      "\n",
      "                                                    f1-score     support  \n",
      "Apple___Apple_scab                                  0.000000    63.00000  \n",
      "Apple___Black_rot                                   0.000000    63.00000  \n",
      "Apple___Cedar_apple_rust                            0.000000    28.00000  \n",
      "Apple___healthy                                     0.000000   165.00000  \n",
      "Blueberry___healthy                                 0.000000   151.00000  \n",
      "Cherry_(including_sour)___Powdery_mildew            0.000000   106.00000  \n",
      "Cherry_(including_sour)___healthy                   0.000000    86.00000  \n",
      "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot  0.000000    52.00000  \n",
      "Corn_(maize)___Common_rust_                         0.000000   120.00000  \n",
      "Corn_(maize)___Northern_Leaf_Blight                 0.000000    99.00000  \n",
      "Corn_(maize)___healthy                              0.000000   117.00000  \n",
      "Grape___Black_rot                                   0.000000   118.00000  \n",
      "Grape___Esca_(Black_Measles)                        0.000000   139.00000  \n",
      "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)          0.000000   109.00000  \n",
      "Grape___healthy                                     0.000000    43.00000  \n",
      "Orange___Haunglongbing_(Citrus_greening)            0.000000   552.00000  \n",
      "Peach___Bacterial_spot                              0.000000   231.00000  \n",
      "Peach___healthy                                     0.000000    36.00000  \n",
      "Pepper,_bell___Bacterial_spot                       0.000000   101.00000  \n",
      "Pepper,_bell___healthy                              0.000000   149.00000  \n",
      "Potato___Early_blight                               0.000000   100.00000  \n",
      "Potato___Late_blight                                0.000000   100.00000  \n",
      "Potato___healthy                                    0.000000    16.00000  \n",
      "Raspberry___healthy                                 0.000000    38.00000  \n",
      "Soybean___healthy                                   0.000000   509.00000  \n",
      "Squash___Powdery_mildew                             0.000000   184.00000  \n",
      "Strawberry___Leaf_scorch                            0.000000   112.00000  \n",
      "Strawberry___healthy                                0.000000    47.00000  \n",
      "Tomato___Bacterial_spot                             0.000000   214.00000  \n",
      "Tomato___Early_blight                               0.000000   100.00000  \n",
      "Tomato___Late_blight                                0.000000   192.00000  \n",
      "Tomato___Leaf_Mold                                  0.000000    96.00000  \n",
      "Tomato___Septoria_leaf_spot                         0.000000   178.00000  \n",
      "Tomato___Spider_mites Two-spotted_spider_mite       0.000000   169.00000  \n",
      "Tomato___Target_Spot                                0.000000   141.00000  \n",
      "Tomato___Tomato_Yellow_Leaf_Curl_Virus              0.179119   537.00000  \n",
      "Tomato___Tomato_mosaic_virus                        0.000000    38.00000  \n",
      "Tomato___healthy                                    0.000000   160.00000  \n",
      "accuracy                                            0.098370     0.09837  \n",
      "macro avg                                           0.004714  5459.00000  \n",
      "weighted avg                                        0.017620  5459.00000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize variables to store results\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "# Evaluation loop\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Move inputs and labels to GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Predictions\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Collect labels and predictions for metrics\n",
    "        all_labels.extend(labels.cpu().numpy())  # Move to CPU for sklearn compatibility\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "\n",
    "# Generate classification report for each class\n",
    "report = classification_report(\n",
    "    all_labels, all_predictions, target_names=class_names, output_dict=True\n",
    ")\n",
    "\n",
    "# Convert the report to a DataFrame for easier saving\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Save the report to a file\n",
    "report_df.to_csv(\"class_specific_metrics_momentum.csv\", index=True)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report_df)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 277323,
     "sourceId": 658267,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6439791,
     "sourceId": 10393979,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
