{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":658267,"sourceType":"datasetVersion","datasetId":277323},{"sourceId":10393979,"sourceType":"datasetVersion","datasetId":6439791}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nfrom collections import defaultdict\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\n\n# Path to the dataset\ndata_dir = '/kaggle/input/plantvillage-dataset/color'\n\n\ndata_transforms = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n])\n\n# Load the full dataset without transformations\nfull_dataset = datasets.ImageFolder(\n    root=data_dir, \n    transform=data_transforms\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:41:21.450592Z","iopub.execute_input":"2025-01-10T19:41:21.450919Z","iopub.status.idle":"2025-01-10T19:42:12.772114Z","shell.execute_reply.started":"2025-01-10T19:41:21.450874Z","shell.execute_reply":"2025-01-10T19:42:12.771381Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Extract image paths and labels\nimage_paths = [sample[0] for sample in full_dataset.samples]\nlabels = [sample[1] for sample in full_dataset.samples]\nclass_names = full_dataset.classes\nnum_classes = len(class_names)\n\n\nprint(f\"Number of classes: {num_classes}\")\nprint(f\"Class names: {class_names}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:42:12.773147Z","iopub.execute_input":"2025-01-10T19:42:12.773489Z","iopub.status.idle":"2025-01-10T19:42:12.784396Z","shell.execute_reply.started":"2025-01-10T19:42:12.773459Z","shell.execute_reply":"2025-01-10T19:42:12.783555Z"}},"outputs":[{"name":"stdout","text":"Number of classes: 38\nClass names: ['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_', 'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy', 'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch', 'Strawberry___healthy', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Create a DataLoader to iterate through the dataset\ndataloader = DataLoader(full_dataset, batch_size=32, shuffle=False, num_workers=2)\n\n# Initialize variables to accumulate pixel values\nmean = 0.0\nstd = 0.0\ntotal_images = 0\n\n# Iterate through the dataset to compute mean and std\nfor images, _ in dataloader:\n    batch_size = images.size(0)  # Number of images in the current batch\n    images = images.view(batch_size, images.size(1), -1)  # Flatten height and width dimensions\n    mean += images.mean(2).sum(0)  # Sum of means for each channel (RGB)\n    std += images.std(2).sum(0)    # Sum of stds for each channel (RGB)\n    total_images += batch_size     # Accumulate total number of images\n\n# Divide by the total number of images to get the average mean and std\nmean /= total_images\nstd /= total_images\n\nprint(f\"Mean: {mean}\")\nprint(f\"Std: {std}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:42:12.785729Z","iopub.execute_input":"2025-01-10T19:42:12.786032Z","iopub.status.idle":"2025-01-10T19:45:21.004871Z","shell.execute_reply.started":"2025-01-10T19:42:12.786010Z","shell.execute_reply":"2025-01-10T19:45:21.003905Z"}},"outputs":[{"name":"stdout","text":"Mean: tensor([0.4664, 0.4891, 0.4104])\nStd: tensor([0.1761, 0.1500, 0.1925])\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Define the transformation pipeline\ndata_transforms = transforms.Compose([\n    transforms.Resize((256, 256)),          # Resize images to 256x256 pixels\n    transforms.ToTensor(),                  # Convert images to PyTorch tensors and scale to [0, 1]\n    transforms.Normalize(mean=mean, std=std)  # Normalize using your dataset's mean and std\n])\n\n# Apply the transformations to the already loaded dataset\nfull_dataset.transform = data_transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:45:21.006235Z","iopub.execute_input":"2025-01-10T19:45:21.006468Z","iopub.status.idle":"2025-01-10T19:45:21.010769Z","shell.execute_reply.started":"2025-01-10T19:45:21.006449Z","shell.execute_reply":"2025-01-10T19:45:21.009848Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Manual stratified splitting\n# Step 1: Organize indices by class\nfrom collections import defaultdict\n\n# Transform the list structure of labels to a dictionnary of lists representing keys and \n# indices representing values\nclass_to_indices = defaultdict(list)\nfor idx, label in enumerate(labels): #idx is the index in the dataset and label is the value at that position\n    class_to_indices[label].append(idx)\n\n# Step 2: Split indices for each class\ntrain_indices = []\nval_indices = []\ntest_indices = []\n\ntrain_ratio = 0.8\nval_ratio = 0.1\ntest_ratio = 0.1\n\nfor label, indices in class_to_indices.items():\n    # Shuffle the indices for this class\n    random.shuffle(indices)\n\n    # Detecting the number of samples in each class\n    n_total = len(indices)\n    n_train = int(train_ratio * n_total)\n    n_val = int(val_ratio * n_total)\n    n_test = n_total - n_train - n_val  # Ensure all samples are used\n\n    # Split the indices\n    train_idx = indices[:n_train]\n    val_idx = indices[n_train:n_train + n_val]\n    test_idx = indices[n_train + n_val:]\n\n    # Append to the respective lists the samples of each class after splitting\n    train_indices.extend(train_idx)\n    val_indices.extend(val_idx)\n    test_indices.extend(test_idx)\n\n# Shuffle the final indices to ensure randomness across classes\nrandom.shuffle(train_indices)\nrandom.shuffle(val_indices)\nrandom.shuffle(test_indices)\n\nprint(f\"Total samples: {len(full_dataset)}\")\nprint(f\"Training samples: {len(train_indices)}\")\nprint(f\"Validation samples: {len(val_indices)}\")\nprint(f\"Testing samples: {len(test_indices)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:45:21.011828Z","iopub.execute_input":"2025-01-10T19:45:21.012137Z","iopub.status.idle":"2025-01-10T19:45:21.084934Z","shell.execute_reply.started":"2025-01-10T19:45:21.012108Z","shell.execute_reply":"2025-01-10T19:45:21.084252Z"}},"outputs":[{"name":"stdout","text":"Total samples: 54305\nTraining samples: 43429\nValidation samples: 5417\nTesting samples: 5459\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from torch.utils.data import Subset\n\n# Create subsets using the indices from the stratified split\ntrain_subset = Subset(full_dataset, train_indices)\nval_subset = Subset(full_dataset, val_indices)\ntest_subset = Subset(full_dataset, test_indices)\n\n# Create DataLoaders\ntrain_loader = DataLoader(\n    train_subset,\n    batch_size=32,\n    shuffle=True,  # Shuffle for training\n)\n\nval_loader = DataLoader(\n    val_subset,\n    batch_size=32,\n    shuffle=False,  # No shuffle for validation\n)\n\ntest_loader = DataLoader(\n    test_subset,\n    batch_size=32,\n    shuffle=False,  # No shuffle for testing\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:45:21.085638Z","iopub.execute_input":"2025-01-10T19:45:21.085890Z","iopub.status.idle":"2025-01-10T19:45:21.090734Z","shell.execute_reply.started":"2025-01-10T19:45:21.085870Z","shell.execute_reply":"2025-01-10T19:45:21.089772Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass PlantDiseaseCNN(nn.Module):\n    def __init__(self):\n        super(PlantDiseaseCNN, self).__init__()\n        \n        # First conv uses a 7x7 kernel to quickly capture wide spatial context.\n        # Then standard 3x3 blocks with pooling.\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=7, stride=2, padding=3)\n        \n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n        \n        self.pool = nn.MaxPool2d(2, 2)\n        \n        # Another pair of 3Ã—3 blocks\n        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n        \n        # Another pooling\n        self.pool2 = nn.MaxPool2d(2, 2)\n\n        # Replace fully connected layer with GAP\n        # GAP reduces each 32x32 feature map to 1x1, resulting in 128 outputs.\n        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(128, 39)  # Match the number of classes\n\n    def forward(self, x):\n        # Large kernel conv + stride\n        x = nn.functional.relu(self.conv1(x))   # [batch, 32, 128, 128]\n        \n        # 2 small conv layers + pool\n        x = nn.functional.relu(self.conv2(x))   # [batch, 64, 128, 128]\n        x = nn.functional.relu(self.conv3(x))   # [batch, 64, 128, 128]\n        x = self.pool(x)                        # -> [batch, 64, 64, 64]\n        \n        # Another 2 small conv + pool\n        x = nn.functional.relu(self.conv4(x))   # [batch, 128, 64, 64]\n        x = nn.functional.relu(self.conv5(x))   # [batch, 128, 64, 64]\n        x = self.pool2(x)                       # -> [batch, 128, 32, 32]\n        \n        # Apply Global Average Pooling\n        x = self.global_avg_pool(x)             # -> [batch, 128, 1, 1]\n        x = x.view(x.size(0), -1)               # Flatten -> [batch, 128]\n        \n        # Final linear layer for classification\n        x = self.fc(x)                          # -> [batch, 39]\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:45:21.091636Z","iopub.execute_input":"2025-01-10T19:45:21.091876Z","iopub.status.idle":"2025-01-10T19:45:21.107872Z","shell.execute_reply.started":"2025-01-10T19:45:21.091857Z","shell.execute_reply":"2025-01-10T19:45:21.107087Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model = PlantDiseaseCNN()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:45:21.109756Z","iopub.execute_input":"2025-01-10T19:45:21.110084Z","iopub.status.idle":"2025-01-10T19:45:21.128685Z","shell.execute_reply.started":"2025-01-10T19:45:21.110062Z","shell.execute_reply":"2025-01-10T19:45:21.127869Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)  # Move the model to GPU\n\nnum_epochs = 10\ntrain_history = []\nval_history = []\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for inputs, labels in train_loader:\n        # Move data to GPU\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    train_accuracy = 100 * correct / total\n    train_loss = running_loss / len(train_loader)\n    train_history.append((train_loss, train_accuracy))\n\n    # Validation Loop\n    model.eval()\n    val_loss = 0.0\n    val_correct = 0\n    val_total = 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            # Move data to GPU\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            val_total += labels.size(0)\n            val_correct += (predicted == labels).sum().item()\n\n    val_accuracy = 100 * val_correct / val_total\n    val_loss /= len(val_loader)\n    val_history.append((val_loss, val_accuracy))\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:45:21.129664Z","iopub.execute_input":"2025-01-10T19:45:21.129894Z","iopub.status.idle":"2025-01-10T20:24:21.983696Z","shell.execute_reply.started":"2025-01-10T19:45:21.129874Z","shell.execute_reply":"2025-01-10T20:24:21.982630Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 2.2999, Train Accuracy: 37.48%\nValidation Loss: 1.6683, Validation Accuracy: 54.13%\nEpoch 2/10\nTrain Loss: 1.4160, Train Accuracy: 59.09%\nValidation Loss: 1.2636, Validation Accuracy: 63.39%\nEpoch 3/10\nTrain Loss: 1.1386, Train Accuracy: 66.63%\nValidation Loss: 1.0700, Validation Accuracy: 70.06%\nEpoch 4/10\nTrain Loss: 0.9732, Train Accuracy: 71.19%\nValidation Loss: 0.9268, Validation Accuracy: 73.18%\nEpoch 5/10\nTrain Loss: 0.8618, Train Accuracy: 74.41%\nValidation Loss: 0.8568, Validation Accuracy: 75.82%\nEpoch 6/10\nTrain Loss: 0.7769, Train Accuracy: 77.14%\nValidation Loss: 0.8334, Validation Accuracy: 75.50%\nEpoch 7/10\nTrain Loss: 0.7114, Train Accuracy: 78.80%\nValidation Loss: 0.7102, Validation Accuracy: 79.18%\nEpoch 8/10\nTrain Loss: 0.6520, Train Accuracy: 80.72%\nValidation Loss: 0.7095, Validation Accuracy: 78.79%\nEpoch 9/10\nTrain Loss: 0.6049, Train Accuracy: 82.07%\nValidation Loss: 0.6301, Validation Accuracy: 81.93%\nEpoch 10/10\nTrain Loss: 0.5522, Train Accuracy: 83.33%\nValidation Loss: 0.5765, Validation Accuracy: 83.05%\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Evaluation\nmodel.eval()\ntest_loss = 0.0\ntest_correct = 0\ntest_total = 0\nwith torch.no_grad():\n    for inputs, labels in val_loader:\n        # Move inputs and labels to the same device as the model\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        test_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        test_total += labels.size(0)\n        test_correct += (predicted == labels).sum().item()\n\ntest_accuracy = 100 * test_correct / test_total\ntest_loss /= len(val_loader)\n\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T20:24:21.984748Z","iopub.execute_input":"2025-01-10T20:24:21.985055Z","iopub.status.idle":"2025-01-10T20:24:39.981352Z","shell.execute_reply.started":"2025-01-10T20:24:21.985031Z","shell.execute_reply":"2025-01-10T20:24:39.980522Z"}},"outputs":[{"name":"stdout","text":"Test Loss: 0.5765, Test Accuracy: 83.05%\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score, recall_score, f1_score, precision_score\n\n# Initialize variables to store results\nall_labels = []\nall_predictions = []\n\n# Evaluation loop\nmodel.eval()\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        # Move inputs and labels to GPU\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # Forward pass\n        outputs = model(inputs)\n\n        # Predictions\n        _, predicted = torch.max(outputs, 1)\n\n        # Collect labels and predictions for metrics\n        all_labels.extend(labels.cpu().numpy())  # Move to CPU for sklearn compatibility\n        all_predictions.extend(predicted.cpu().numpy())\n\n# Calculate metrics\naccuracy = accuracy_score(all_labels, all_predictions)\nrecall = recall_score(all_labels, all_predictions, average=\"weighted\")  # Weighted for multi-class\nprecision = precision_score(all_labels, all_predictions, average=\"weighted\")  # Weighted for multi-class\nf1 = f1_score(all_labels, all_predictions, average=\"weighted\")  # Weighted for multi-class\n\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\n\n# Detailed classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(all_labels, all_predictions, target_names=class_names))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T20:24:39.982353Z","iopub.execute_input":"2025-01-10T20:24:39.982717Z","iopub.status.idle":"2025-01-10T20:25:02.624279Z","shell.execute_reply.started":"2025-01-10T20:24:39.982679Z","shell.execute_reply":"2025-01-10T20:25:02.623393Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 84.91%\nPrecision: 0.8595\nRecall: 0.8491\nF1 Score: 0.8497\n\nClassification Report:\n                                                    precision    recall  f1-score   support\n\n                                Apple___Apple_scab       0.73      0.56      0.63        63\n                                 Apple___Black_rot       0.86      0.86      0.86        63\n                          Apple___Cedar_apple_rust       0.47      0.32      0.38        28\n                                   Apple___healthy       0.80      0.82      0.81       165\n                               Blueberry___healthy       0.97      0.89      0.93       151\n          Cherry_(including_sour)___Powdery_mildew       0.63      0.81      0.71       106\n                 Cherry_(including_sour)___healthy       0.95      0.86      0.90        86\nCorn_(maize)___Cercospora_leaf_spot Gray_leaf_spot       0.71      0.58      0.64        52\n                       Corn_(maize)___Common_rust_       1.00      0.97      0.99       120\n               Corn_(maize)___Northern_Leaf_Blight       0.80      0.86      0.83        99\n                            Corn_(maize)___healthy       1.00      1.00      1.00       117\n                                 Grape___Black_rot       0.75      0.62      0.68       118\n                      Grape___Esca_(Black_Measles)       0.90      0.88      0.89       139\n        Grape___Leaf_blight_(Isariopsis_Leaf_Spot)       0.82      0.94      0.88       109\n                                   Grape___healthy       0.36      0.95      0.52        43\n          Orange___Haunglongbing_(Citrus_greening)       0.97      0.98      0.97       552\n                            Peach___Bacterial_spot       0.81      0.79      0.80       231\n                                   Peach___healthy       0.81      0.94      0.87        36\n                     Pepper,_bell___Bacterial_spot       0.83      0.80      0.81       101\n                            Pepper,_bell___healthy       0.75      0.80      0.78       149\n                             Potato___Early_blight       0.85      0.86      0.86       100\n                              Potato___Late_blight       0.61      0.77      0.68       100\n                                  Potato___healthy       0.93      0.81      0.87        16\n                               Raspberry___healthy       0.65      0.89      0.76        38\n                                 Soybean___healthy       0.98      0.82      0.89       509\n                           Squash___Powdery_mildew       0.88      0.99      0.93       184\n                          Strawberry___Leaf_scorch       0.79      0.88      0.84       112\n                              Strawberry___healthy       1.00      0.85      0.92        47\n                           Tomato___Bacterial_spot       0.82      0.90      0.86       214\n                             Tomato___Early_blight       0.73      0.38      0.50       100\n                              Tomato___Late_blight       0.79      0.71      0.75       192\n                                Tomato___Leaf_Mold       0.89      0.83      0.86        96\n                       Tomato___Septoria_leaf_spot       0.72      0.72      0.72       178\n     Tomato___Spider_mites Two-spotted_spider_mite       0.75      0.80      0.78       169\n                              Tomato___Target_Spot       0.78      0.82      0.80       141\n            Tomato___Tomato_Yellow_Leaf_Curl_Virus       0.97      0.92      0.94       537\n                      Tomato___Tomato_mosaic_virus       0.86      0.95      0.90        38\n                                  Tomato___healthy       0.91      0.99      0.95       160\n\n                                          accuracy                           0.85      5459\n                                         macro avg       0.81      0.82      0.81      5459\n                                      weighted avg       0.86      0.85      0.85      5459\n\n","output_type":"stream"}],"execution_count":11}]}