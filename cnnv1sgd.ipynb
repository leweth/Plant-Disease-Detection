{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":658267,"sourceType":"datasetVersion","datasetId":277323},{"sourceId":10393979,"sourceType":"datasetVersion","datasetId":6439791}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nfrom collections import defaultdict\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\n\n# Path to the dataset\ndata_dir = '/kaggle/input/plantvillage-dataset/color'\n\n\ndata_transforms = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n])\n\n# Load the full dataset without transformations\nfull_dataset = datasets.ImageFolder(\n    root=data_dir, \n    transform=data_transforms\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:33:41.286842Z","iopub.execute_input":"2025-01-10T21:33:41.287063Z","iopub.status.idle":"2025-01-10T21:33:52.799503Z","shell.execute_reply.started":"2025-01-10T21:33:41.287043Z","shell.execute_reply":"2025-01-10T21:33:52.798796Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Extract image paths and labels\nimage_paths = [sample[0] for sample in full_dataset.samples]\nlabels = [sample[1] for sample in full_dataset.samples]\nclass_names = full_dataset.classes\nnum_classes = len(class_names)\n\n\nprint(f\"Number of classes: {num_classes}\")\nprint(f\"Class names: {class_names}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:33:52.800849Z","iopub.execute_input":"2025-01-10T21:33:52.801255Z","iopub.status.idle":"2025-01-10T21:33:52.811764Z","shell.execute_reply.started":"2025-01-10T21:33:52.801231Z","shell.execute_reply":"2025-01-10T21:33:52.810827Z"}},"outputs":[{"name":"stdout","text":"Number of classes: 38\nClass names: ['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_', 'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy', 'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch', 'Strawberry___healthy', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Create a DataLoader to iterate through the dataset\ndataloader = DataLoader(full_dataset, batch_size=32, shuffle=False, num_workers=2)\n\n# Initialize variables to accumulate pixel values\nmean = 0.0\nstd = 0.0\ntotal_images = 0\n\n# Iterate through the dataset to compute mean and std\nfor images, _ in dataloader:\n    batch_size = images.size(0)  # Number of images in the current batch\n    images = images.view(batch_size, images.size(1), -1)  # Flatten height and width dimensions\n    mean += images.mean(2).sum(0)  # Sum of means for each channel (RGB)\n    std += images.std(2).sum(0)    # Sum of stds for each channel (RGB)\n    total_images += batch_size     # Accumulate total number of images\n\n# Divide by the total number of images to get the average mean and std\nmean /= total_images\nstd /= total_images\n\nprint(f\"Mean: {mean}\")\nprint(f\"Std: {std}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:33:52.812846Z","iopub.execute_input":"2025-01-10T21:33:52.813110Z","iopub.status.idle":"2025-01-10T21:36:09.541420Z","shell.execute_reply.started":"2025-01-10T21:33:52.813089Z","shell.execute_reply":"2025-01-10T21:36:09.540417Z"}},"outputs":[{"name":"stdout","text":"Mean: tensor([0.4664, 0.4891, 0.4104])\nStd: tensor([0.1761, 0.1500, 0.1925])\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Define the transformation pipeline\ndata_transforms = transforms.Compose([\n    transforms.Resize((256, 256)),          # Resize images to 256x256 pixels\n    transforms.ToTensor(),                  # Convert images to PyTorch tensors and scale to [0, 1]\n    transforms.Normalize(mean=mean, std=std)  # Normalize using your dataset's mean and std\n])\n\n# Apply the transformations to the already loaded dataset\nfull_dataset.transform = data_transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:36:09.542664Z","iopub.execute_input":"2025-01-10T21:36:09.543003Z","iopub.status.idle":"2025-01-10T21:36:09.547124Z","shell.execute_reply.started":"2025-01-10T21:36:09.542972Z","shell.execute_reply":"2025-01-10T21:36:09.546313Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Manual stratified splitting\n# Step 1: Organize indices by class\nfrom collections import defaultdict\n\n# Transform the list structure of labels to a dictionnary of lists representing keys and \n# indices representing values\nclass_to_indices = defaultdict(list)\nfor idx, label in enumerate(labels): #idx is the index in the dataset and label is the value at that position\n    class_to_indices[label].append(idx)\n\n# Step 2: Split indices for each class\ntrain_indices = []\nval_indices = []\ntest_indices = []\n\ntrain_ratio = 0.8\nval_ratio = 0.1\ntest_ratio = 0.1\n\nfor label, indices in class_to_indices.items():\n    # Shuffle the indices for this class\n    random.shuffle(indices)\n\n    # Detecting the number of samples in each class\n    n_total = len(indices)\n    n_train = int(train_ratio * n_total)\n    n_val = int(val_ratio * n_total)\n    n_test = n_total - n_train - n_val  # Ensure all samples are used\n\n    # Split the indices\n    train_idx = indices[:n_train]\n    val_idx = indices[n_train:n_train + n_val]\n    test_idx = indices[n_train + n_val:]\n\n    # Append to the respective lists the samples of each class after splitting\n    train_indices.extend(train_idx)\n    val_indices.extend(val_idx)\n    test_indices.extend(test_idx)\n\n# Shuffle the final indices to ensure randomness across classes\nrandom.shuffle(train_indices)\nrandom.shuffle(val_indices)\nrandom.shuffle(test_indices)\n\nprint(f\"Total samples: {len(full_dataset)}\")\nprint(f\"Training samples: {len(train_indices)}\")\nprint(f\"Validation samples: {len(val_indices)}\")\nprint(f\"Testing samples: {len(test_indices)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:36:09.548125Z","iopub.execute_input":"2025-01-10T21:36:09.548357Z","iopub.status.idle":"2025-01-10T21:36:09.621621Z","shell.execute_reply.started":"2025-01-10T21:36:09.548337Z","shell.execute_reply":"2025-01-10T21:36:09.620985Z"}},"outputs":[{"name":"stdout","text":"Total samples: 54305\nTraining samples: 43429\nValidation samples: 5417\nTesting samples: 5459\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from torch.utils.data import Subset\n\n# Create subsets using the indices from the stratified split\ntrain_subset = Subset(full_dataset, train_indices)\nval_subset = Subset(full_dataset, val_indices)\ntest_subset = Subset(full_dataset, test_indices)\n\n# Create DataLoaders\ntrain_loader = DataLoader(\n    train_subset,\n    batch_size=32,\n    shuffle=True,  # Shuffle for training\n)\n\nval_loader = DataLoader(\n    val_subset,\n    batch_size=32,\n    shuffle=False,  # No shuffle for validation\n)\n\ntest_loader = DataLoader(\n    test_subset,\n    batch_size=32,\n    shuffle=False,  # No shuffle for testing\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:36:09.622348Z","iopub.execute_input":"2025-01-10T21:36:09.622542Z","iopub.status.idle":"2025-01-10T21:36:09.627412Z","shell.execute_reply.started":"2025-01-10T21:36:09.622525Z","shell.execute_reply":"2025-01-10T21:36:09.626541Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass PlantDiseaseCNN(nn.Module):\n    def __init__(self):\n        super(PlantDiseaseCNN, self).__init__()\n        \n        # First conv uses a 7x7 kernel to quickly capture wide spatial context.\n        # Then standard 3x3 blocks with pooling.\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=7, stride=2, padding=3)\n        \n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n        \n        self.pool = nn.MaxPool2d(2, 2)\n        \n        # Another pair of 3Ã—3 blocks\n        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n        \n        # Another pooling\n        self.pool2 = nn.MaxPool2d(2, 2)\n\n        # Replace fully connected layer with GAP\n        # GAP reduces each 32x32 feature map to 1x1, resulting in 128 outputs.\n        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(128, 39)  # Match the number of classes\n\n    def forward(self, x):\n        # Large kernel conv + stride\n        x = nn.functional.relu(self.conv1(x))   # [batch, 32, 128, 128]\n        \n        # 2 small conv layers + pool\n        x = nn.functional.relu(self.conv2(x))   # [batch, 64, 128, 128]\n        x = nn.functional.relu(self.conv3(x))   # [batch, 64, 128, 128]\n        x = self.pool(x)                        # -> [batch, 64, 64, 64]\n        \n        # Another 2 small conv + pool\n        x = nn.functional.relu(self.conv4(x))   # [batch, 128, 64, 64]\n        x = nn.functional.relu(self.conv5(x))   # [batch, 128, 64, 64]\n        x = self.pool2(x)                       # -> [batch, 128, 32, 32]\n        \n        # Apply Global Average Pooling\n        x = self.global_avg_pool(x)             # -> [batch, 128, 1, 1]\n        x = x.view(x.size(0), -1)               # Flatten -> [batch, 128]\n        \n        # Final linear layer for classification\n        x = self.fc(x)                          # -> [batch, 39]\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:36:09.628165Z","iopub.execute_input":"2025-01-10T21:36:09.628452Z","iopub.status.idle":"2025-01-10T21:36:09.640418Z","shell.execute_reply.started":"2025-01-10T21:36:09.628432Z","shell.execute_reply":"2025-01-10T21:36:09.639718Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model = PlantDiseaseCNN()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.0001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:36:09.642551Z","iopub.execute_input":"2025-01-10T21:36:09.642754Z","iopub.status.idle":"2025-01-10T21:36:09.662229Z","shell.execute_reply.started":"2025-01-10T21:36:09.642736Z","shell.execute_reply":"2025-01-10T21:36:09.661616Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)  # Move the model to GPU\n\nnum_epochs = 10\ntrain_history = []\nval_history = []\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for inputs, labels in train_loader:\n        # Move data to GPU\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    train_accuracy = 100 * correct / total\n    train_loss = running_loss / len(train_loader)\n    train_history.append((train_loss, train_accuracy))\n\n    # Validation Loop\n    model.eval()\n    val_loss = 0.0\n    val_correct = 0\n    val_total = 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            # Move data to GPU\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            val_total += labels.size(0)\n            val_correct += (predicted == labels).sum().item()\n\n    val_accuracy = 100 * val_correct / val_total\n    val_loss /= len(val_loader)\n    val_history.append((val_loss, val_accuracy))\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:36:09.663244Z","iopub.execute_input":"2025-01-10T21:36:09.663547Z","iopub.status.idle":"2025-01-10T22:14:15.003131Z","shell.execute_reply.started":"2025-01-10T21:36:09.663518Z","shell.execute_reply":"2025-01-10T22:14:15.002165Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 3.6629, Train Accuracy: 3.57%\nValidation Loss: 3.6607, Validation Accuracy: 6.20%\nEpoch 2/10\nTrain Loss: 3.6586, Train Accuracy: 9.86%\nValidation Loss: 3.6564, Validation Accuracy: 9.91%\nEpoch 3/10\nTrain Loss: 3.6543, Train Accuracy: 9.87%\nValidation Loss: 3.6522, Validation Accuracy: 9.88%\nEpoch 4/10\nTrain Loss: 3.6500, Train Accuracy: 9.87%\nValidation Loss: 3.6479, Validation Accuracy: 9.88%\nEpoch 5/10\nTrain Loss: 3.6458, Train Accuracy: 9.87%\nValidation Loss: 3.6437, Validation Accuracy: 9.88%\nEpoch 6/10\nTrain Loss: 3.6415, Train Accuracy: 9.87%\nValidation Loss: 3.6393, Validation Accuracy: 9.88%\nEpoch 7/10\nTrain Loss: 3.6371, Train Accuracy: 9.87%\nValidation Loss: 3.6349, Validation Accuracy: 9.88%\nEpoch 8/10\nTrain Loss: 3.6325, Train Accuracy: 9.87%\nValidation Loss: 3.6302, Validation Accuracy: 9.88%\nEpoch 9/10\nTrain Loss: 3.6277, Train Accuracy: 9.87%\nValidation Loss: 3.6253, Validation Accuracy: 9.88%\nEpoch 10/10\nTrain Loss: 3.6226, Train Accuracy: 9.87%\nValidation Loss: 3.6199, Validation Accuracy: 9.88%\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Evaluation\nmodel.eval()\ntest_loss = 0.0\ntest_correct = 0\ntest_total = 0\nwith torch.no_grad():\n    for inputs, labels in val_loader:\n        # Move inputs and labels to the same device as the model\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        test_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        test_total += labels.size(0)\n        test_correct += (predicted == labels).sum().item()\n\ntest_accuracy = 100 * test_correct / test_total\ntest_loss /= len(val_loader)\n\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T22:14:15.004184Z","iopub.execute_input":"2025-01-10T22:14:15.004473Z","iopub.status.idle":"2025-01-10T22:14:31.743013Z","shell.execute_reply.started":"2025-01-10T22:14:15.004438Z","shell.execute_reply":"2025-01-10T22:14:31.742117Z"}},"outputs":[{"name":"stdout","text":"Test Loss: 3.6199, Test Accuracy: 9.88%\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score, recall_score, f1_score, precision_score\n\n# Initialize variables to store results\nall_labels = []\nall_predictions = []\n\n# Evaluation loop\nmodel.eval()\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        # Move inputs and labels to GPU\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # Forward pass\n        outputs = model(inputs)\n\n        # Predictions\n        _, predicted = torch.max(outputs, 1)\n\n        # Collect labels and predictions for metrics\n        all_labels.extend(labels.cpu().numpy())  # Move to CPU for sklearn compatibility\n        all_predictions.extend(predicted.cpu().numpy())\n\n# Calculate metrics\naccuracy = accuracy_score(all_labels, all_predictions)\nrecall = recall_score(all_labels, all_predictions, average=\"weighted\")  # Weighted for multi-class\nprecision = precision_score(all_labels, all_predictions, average=\"weighted\")  # Weighted for multi-class\nf1 = f1_score(all_labels, all_predictions, average=\"weighted\")  # Weighted for multi-class\n\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\n\n# Detailed classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(all_labels, all_predictions, target_names=class_names))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T22:14:31.743808Z","iopub.execute_input":"2025-01-10T22:14:31.744021Z","iopub.status.idle":"2025-01-10T22:14:53.650244Z","shell.execute_reply.started":"2025-01-10T22:14:31.744003Z","shell.execute_reply":"2025-01-10T22:14:53.649261Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 9.84%\nPrecision: 0.0097\nRecall: 0.0984\nF1 Score: 0.0176\n\nClassification Report:\n                                                    precision    recall  f1-score   support\n\n                                Apple___Apple_scab       0.00      0.00      0.00        63\n                                 Apple___Black_rot       0.00      0.00      0.00        63\n                          Apple___Cedar_apple_rust       0.00      0.00      0.00        28\n                                   Apple___healthy       0.00      0.00      0.00       165\n                               Blueberry___healthy       0.00      0.00      0.00       151\n          Cherry_(including_sour)___Powdery_mildew       0.00      0.00      0.00       106\n                 Cherry_(including_sour)___healthy       0.00      0.00      0.00        86\nCorn_(maize)___Cercospora_leaf_spot Gray_leaf_spot       0.00      0.00      0.00        52\n                       Corn_(maize)___Common_rust_       0.00      0.00      0.00       120\n               Corn_(maize)___Northern_Leaf_Blight       0.00      0.00      0.00        99\n                            Corn_(maize)___healthy       0.00      0.00      0.00       117\n                                 Grape___Black_rot       0.00      0.00      0.00       118\n                      Grape___Esca_(Black_Measles)       0.00      0.00      0.00       139\n        Grape___Leaf_blight_(Isariopsis_Leaf_Spot)       0.00      0.00      0.00       109\n                                   Grape___healthy       0.00      0.00      0.00        43\n          Orange___Haunglongbing_(Citrus_greening)       0.00      0.00      0.00       552\n                            Peach___Bacterial_spot       0.00      0.00      0.00       231\n                                   Peach___healthy       0.00      0.00      0.00        36\n                     Pepper,_bell___Bacterial_spot       0.00      0.00      0.00       101\n                            Pepper,_bell___healthy       0.00      0.00      0.00       149\n                             Potato___Early_blight       0.00      0.00      0.00       100\n                              Potato___Late_blight       0.00      0.00      0.00       100\n                                  Potato___healthy       0.00      0.00      0.00        16\n                               Raspberry___healthy       0.00      0.00      0.00        38\n                                 Soybean___healthy       0.00      0.00      0.00       509\n                           Squash___Powdery_mildew       0.00      0.00      0.00       184\n                          Strawberry___Leaf_scorch       0.00      0.00      0.00       112\n                              Strawberry___healthy       0.00      0.00      0.00        47\n                           Tomato___Bacterial_spot       0.00      0.00      0.00       214\n                             Tomato___Early_blight       0.00      0.00      0.00       100\n                              Tomato___Late_blight       0.00      0.00      0.00       192\n                                Tomato___Leaf_Mold       0.00      0.00      0.00        96\n                       Tomato___Septoria_leaf_spot       0.00      0.00      0.00       178\n     Tomato___Spider_mites Two-spotted_spider_mite       0.00      0.00      0.00       169\n                              Tomato___Target_Spot       0.00      0.00      0.00       141\n            Tomato___Tomato_Yellow_Leaf_Curl_Virus       0.10      1.00      0.18       537\n                      Tomato___Tomato_mosaic_virus       0.00      0.00      0.00        38\n                                  Tomato___healthy       0.00      0.00      0.00       160\n\n                                          accuracy                           0.10      5459\n                                         macro avg       0.00      0.03      0.00      5459\n                                      weighted avg       0.01      0.10      0.02      5459\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":11}]}