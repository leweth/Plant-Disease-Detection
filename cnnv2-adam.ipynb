{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":658267,"sourceType":"datasetVersion","datasetId":277323},{"sourceId":10393979,"sourceType":"datasetVersion","datasetId":6439791}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nfrom collections import defaultdict\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\n\n# Path to the dataset\ndata_dir = '/kaggle/input/plantvillage-dataset/color'\n\n\ndata_transforms = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n])\n\n# Load the full dataset without transformations\nfull_dataset = datasets.ImageFolder(\n    root=data_dir, \n    transform=data_transforms\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T18:45:45.525887Z","iopub.execute_input":"2025-01-10T18:45:45.526184Z","iopub.status.idle":"2025-01-10T18:47:02.331048Z","shell.execute_reply.started":"2025-01-10T18:45:45.526150Z","shell.execute_reply":"2025-01-10T18:47:02.330294Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Extract image paths and labels\nimage_paths = [sample[0] for sample in full_dataset.samples]\nlabels = [sample[1] for sample in full_dataset.samples]\nclass_names = full_dataset.classes\nnum_classes = len(class_names)\n\n\nprint(f\"Number of classes: {num_classes}\")\nprint(f\"Class names: {class_names}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T18:47:02.332411Z","iopub.execute_input":"2025-01-10T18:47:02.332804Z","iopub.status.idle":"2025-01-10T18:47:02.344429Z","shell.execute_reply.started":"2025-01-10T18:47:02.332768Z","shell.execute_reply":"2025-01-10T18:47:02.343615Z"}},"outputs":[{"name":"stdout","text":"Number of classes: 38\nClass names: ['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_', 'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy', 'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch', 'Strawberry___healthy', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Create a DataLoader to iterate through the dataset\ndataloader = DataLoader(full_dataset, batch_size=32, shuffle=False, num_workers=2)\n\n# Initialize variables to accumulate pixel values\nmean = 0.0\nstd = 0.0\ntotal_images = 0\n\n# Iterate through the dataset to compute mean and std\nfor images, _ in dataloader:\n    batch_size = images.size(0)  # Number of images in the current batch\n    images = images.view(batch_size, images.size(1), -1)  # Flatten height and width dimensions\n    mean += images.mean(2).sum(0)  # Sum of means for each channel (RGB)\n    std += images.std(2).sum(0)    # Sum of stds for each channel (RGB)\n    total_images += batch_size     # Accumulate total number of images\n\n# Divide by the total number of images to get the average mean and std\nmean /= total_images\nstd /= total_images\n\nprint(f\"Mean: {mean}\")\nprint(f\"Std: {std}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T18:47:02.346069Z","iopub.execute_input":"2025-01-10T18:47:02.346387Z","iopub.status.idle":"2025-01-10T18:51:37.487705Z","shell.execute_reply.started":"2025-01-10T18:47:02.346363Z","shell.execute_reply":"2025-01-10T18:51:37.486758Z"}},"outputs":[{"name":"stdout","text":"Mean: tensor([0.4664, 0.4891, 0.4104])\nStd: tensor([0.1761, 0.1500, 0.1925])\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Define the transformation pipeline\ndata_transforms = transforms.Compose([\n    transforms.Resize((256, 256)),          # Resize images to 256x256 pixels\n    transforms.ToTensor(),                  # Convert images to PyTorch tensors and scale to [0, 1]\n    transforms.Normalize(mean=mean, std=std)  # Normalize using your dataset's mean and std\n])\n\n# Apply the transformations to the already loaded dataset\nfull_dataset.transform = data_transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T18:51:37.488714Z","iopub.execute_input":"2025-01-10T18:51:37.489007Z","iopub.status.idle":"2025-01-10T18:51:37.493410Z","shell.execute_reply.started":"2025-01-10T18:51:37.488983Z","shell.execute_reply":"2025-01-10T18:51:37.492644Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Manual stratified splitting\n# Step 1: Organize indices by class\nfrom collections import defaultdict\n\n# Transform the list structure of labels to a dictionnary of lists representing keys and \n# indices representing values\nclass_to_indices = defaultdict(list)\nfor idx, label in enumerate(labels): #idx is the index in the dataset and label is the value at that position\n    class_to_indices[label].append(idx)\n\n# Step 2: Split indices for each class\ntrain_indices = []\nval_indices = []\ntest_indices = []\n\ntrain_ratio = 0.8\nval_ratio = 0.1\ntest_ratio = 0.1\n\nfor label, indices in class_to_indices.items():\n    # Shuffle the indices for this class\n    random.shuffle(indices)\n\n    # Detecting the number of samples in each class\n    n_total = len(indices)\n    n_train = int(train_ratio * n_total)\n    n_val = int(val_ratio * n_total)\n    n_test = n_total - n_train - n_val  # Ensure all samples are used\n\n    # Split the indices\n    train_idx = indices[:n_train]\n    val_idx = indices[n_train:n_train + n_val]\n    test_idx = indices[n_train + n_val:]\n\n    # Append to the respective lists the samples of each class after splitting\n    train_indices.extend(train_idx)\n    val_indices.extend(val_idx)\n    test_indices.extend(test_idx)\n\n# Shuffle the final indices to ensure randomness across classes\nrandom.shuffle(train_indices)\nrandom.shuffle(val_indices)\nrandom.shuffle(test_indices)\n\nprint(f\"Total samples: {len(full_dataset)}\")\nprint(f\"Training samples: {len(train_indices)}\")\nprint(f\"Validation samples: {len(val_indices)}\")\nprint(f\"Testing samples: {len(test_indices)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T18:51:37.494222Z","iopub.execute_input":"2025-01-10T18:51:37.494438Z","iopub.status.idle":"2025-01-10T18:51:37.569783Z","shell.execute_reply.started":"2025-01-10T18:51:37.494411Z","shell.execute_reply":"2025-01-10T18:51:37.568877Z"}},"outputs":[{"name":"stdout","text":"Total samples: 54305\nTraining samples: 43429\nValidation samples: 5417\nTesting samples: 5459\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from torch.utils.data import Subset\n\n# Create subsets using the indices from the stratified split\ntrain_subset = Subset(full_dataset, train_indices)\nval_subset = Subset(full_dataset, val_indices)\ntest_subset = Subset(full_dataset, test_indices)\n\n# Create DataLoaders\ntrain_loader = DataLoader(\n    train_subset,\n    batch_size=32,\n    shuffle=True,  # Shuffle for training\n)\n\nval_loader = DataLoader(\n    val_subset,\n    batch_size=32,\n    shuffle=False,  # No shuffle for validation\n)\n\ntest_loader = DataLoader(\n    test_subset,\n    batch_size=32,\n    shuffle=False,  # No shuffle for testing\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T18:51:37.570798Z","iopub.execute_input":"2025-01-10T18:51:37.571037Z","iopub.status.idle":"2025-01-10T18:51:37.576687Z","shell.execute_reply.started":"2025-01-10T18:51:37.571015Z","shell.execute_reply":"2025-01-10T18:51:37.575599Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass PlantDiseaseCNN_v1(nn.Module):\n    def __init__(self):\n        super(PlantDiseaseCNN_v1, self).__init__()\n        self.conv_layers = nn.Sequential(\n            # Block 1\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            # Block 2\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            # Block 3\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            # Block 4\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        self.flatten = nn.Flatten()\n        self.fc_layers = nn.Sequential(\n            nn.Dropout(0.25),\n            nn.Linear(256 * 16 * 16, 1024),  # dimension depends on input size\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.Linear(1024, 39)\n        )\n\n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = self.flatten(x)\n        x = self.fc_layers(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T18:51:37.578969Z","iopub.execute_input":"2025-01-10T18:51:37.579220Z","iopub.status.idle":"2025-01-10T18:51:37.591924Z","shell.execute_reply.started":"2025-01-10T18:51:37.579199Z","shell.execute_reply":"2025-01-10T18:51:37.591024Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model = PlantDiseaseCNN_v1()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T18:51:37.593051Z","iopub.execute_input":"2025-01-10T18:51:37.593360Z","iopub.status.idle":"2025-01-10T18:51:38.154578Z","shell.execute_reply.started":"2025-01-10T18:51:37.593335Z","shell.execute_reply":"2025-01-10T18:51:38.153927Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)  # Move the model to GPU\n\nnum_epochs = 10\ntrain_history = []\nval_history = []\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for inputs, labels in train_loader:\n        # Move data to GPU\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    train_accuracy = 100 * correct / total\n    train_loss = running_loss / len(train_loader)\n    train_history.append((train_loss, train_accuracy))\n\n    # Validation Loop\n    model.eval()\n    val_loss = 0.0\n    val_correct = 0\n    val_total = 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            # Move data to GPU\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            val_total += labels.size(0)\n            val_correct += (predicted == labels).sum().item()\n\n    val_accuracy = 100 * val_correct / val_total\n    val_loss /= len(val_loader)\n    val_history.append((val_loss, val_accuracy))\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T18:51:38.155444Z","iopub.execute_input":"2025-01-10T18:51:38.155843Z","iopub.status.idle":"2025-01-10T19:33:20.986343Z","shell.execute_reply.started":"2025-01-10T18:51:38.155801Z","shell.execute_reply":"2025-01-10T19:33:20.985487Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 0.9720, Train Accuracy: 71.85%\nValidation Loss: 0.3997, Validation Accuracy: 87.82%\nEpoch 2/10\nTrain Loss: 0.3682, Train Accuracy: 88.46%\nValidation Loss: 0.2414, Validation Accuracy: 92.67%\nEpoch 3/10\nTrain Loss: 0.2228, Train Accuracy: 92.97%\nValidation Loss: 0.1715, Validation Accuracy: 94.61%\nEpoch 4/10\nTrain Loss: 0.1396, Train Accuracy: 95.39%\nValidation Loss: 0.1277, Validation Accuracy: 96.09%\nEpoch 5/10\nTrain Loss: 0.0999, Train Accuracy: 96.80%\nValidation Loss: 0.1275, Validation Accuracy: 96.10%\nEpoch 6/10\nTrain Loss: 0.0712, Train Accuracy: 97.70%\nValidation Loss: 0.1246, Validation Accuracy: 96.09%\nEpoch 7/10\nTrain Loss: 0.0576, Train Accuracy: 98.19%\nValidation Loss: 0.1177, Validation Accuracy: 96.25%\nEpoch 8/10\nTrain Loss: 0.0435, Train Accuracy: 98.59%\nValidation Loss: 0.1306, Validation Accuracy: 96.20%\nEpoch 9/10\nTrain Loss: 0.0390, Train Accuracy: 98.69%\nValidation Loss: 0.1057, Validation Accuracy: 96.95%\nEpoch 10/10\nTrain Loss: 0.0371, Train Accuracy: 98.77%\nValidation Loss: 0.1093, Validation Accuracy: 97.05%\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Evaluation\nmodel.eval()\ntest_loss = 0.0\ntest_correct = 0\ntest_total = 0\nwith torch.no_grad():\n    for inputs, labels in val_loader:\n        # Move inputs and labels to the same device as the model\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        test_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        test_total += labels.size(0)\n        test_correct += (predicted == labels).sum().item()\n\ntest_accuracy = 100 * test_correct / test_total\ntest_loss /= len(val_loader)\n\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:33:20.987110Z","iopub.execute_input":"2025-01-10T19:33:20.987322Z","iopub.status.idle":"2025-01-10T19:33:38.579774Z","shell.execute_reply.started":"2025-01-10T19:33:20.987303Z","shell.execute_reply":"2025-01-10T19:33:38.578965Z"}},"outputs":[{"name":"stdout","text":"Test Loss: 0.1093, Test Accuracy: 97.05%\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score, recall_score, f1_score, precision_score\n\n# Initialize variables to store results\nall_labels = []\nall_predictions = []\n\n# Evaluation loop\nmodel.eval()\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        # Move inputs and labels to GPU\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # Forward pass\n        outputs = model(inputs)\n\n        # Predictions\n        _, predicted = torch.max(outputs, 1)\n\n        # Collect labels and predictions for metrics\n        all_labels.extend(labels.cpu().numpy())  # Move to CPU for sklearn compatibility\n        all_predictions.extend(predicted.cpu().numpy())\n\n# Calculate metrics\naccuracy = accuracy_score(all_labels, all_predictions)\nrecall = recall_score(all_labels, all_predictions, average=\"weighted\")  # Weighted for multi-class\nprecision = precision_score(all_labels, all_predictions, average=\"weighted\")  # Weighted for multi-class\nf1 = f1_score(all_labels, all_predictions, average=\"weighted\")  # Weighted for multi-class\n\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\n\n# Detailed classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(all_labels, all_predictions, target_names=class_names))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:33:38.580555Z","iopub.execute_input":"2025-01-10T19:33:38.580812Z","iopub.status.idle":"2025-01-10T19:34:02.192082Z","shell.execute_reply.started":"2025-01-10T19:33:38.580789Z","shell.execute_reply":"2025-01-10T19:34:02.190999Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 96.39%\nPrecision: 0.9650\nRecall: 0.9639\nF1 Score: 0.9635\n\nClassification Report:\n                                                    precision    recall  f1-score   support\n\n                                Apple___Apple_scab       0.91      0.81      0.86        63\n                                 Apple___Black_rot       0.98      0.90      0.94        63\n                          Apple___Cedar_apple_rust       1.00      0.93      0.96        28\n                                   Apple___healthy       0.91      0.95      0.93       165\n                               Blueberry___healthy       0.98      0.99      0.98       151\n          Cherry_(including_sour)___Powdery_mildew       0.95      0.98      0.97       106\n                 Cherry_(including_sour)___healthy       0.99      1.00      0.99        86\nCorn_(maize)___Cercospora_leaf_spot Gray_leaf_spot       0.90      0.71      0.80        52\n                       Corn_(maize)___Common_rust_       0.99      0.99      0.99       120\n               Corn_(maize)___Northern_Leaf_Blight       0.84      0.98      0.90        99\n                            Corn_(maize)___healthy       0.99      1.00      1.00       117\n                                 Grape___Black_rot       0.94      0.98      0.96       118\n                      Grape___Esca_(Black_Measles)       0.98      0.96      0.97       139\n        Grape___Leaf_blight_(Isariopsis_Leaf_Spot)       0.99      0.98      0.99       109\n                                   Grape___healthy       0.98      0.95      0.96        43\n          Orange___Haunglongbing_(Citrus_greening)       0.99      1.00      0.99       552\n                            Peach___Bacterial_spot       0.97      0.97      0.97       231\n                                   Peach___healthy       0.97      0.97      0.97        36\n                     Pepper,_bell___Bacterial_spot       0.95      0.96      0.96       101\n                            Pepper,_bell___healthy       0.99      0.99      0.99       149\n                             Potato___Early_blight       0.97      0.94      0.95       100\n                              Potato___Late_blight       0.89      0.92      0.91       100\n                                  Potato___healthy       1.00      0.75      0.86        16\n                               Raspberry___healthy       0.97      0.97      0.97        38\n                                 Soybean___healthy       0.99      0.99      0.99       509\n                           Squash___Powdery_mildew       0.98      0.98      0.98       184\n                          Strawberry___Leaf_scorch       0.97      0.96      0.97       112\n                              Strawberry___healthy       1.00      0.98      0.99        47\n                           Tomato___Bacterial_spot       0.99      0.94      0.97       214\n                             Tomato___Early_blight       0.91      0.70      0.79       100\n                              Tomato___Late_blight       0.83      0.97      0.90       192\n                                Tomato___Leaf_Mold       0.92      0.97      0.94        96\n                       Tomato___Septoria_leaf_spot       0.98      0.88      0.93       178\n     Tomato___Spider_mites Two-spotted_spider_mite       0.97      0.97      0.97       169\n                              Tomato___Target_Spot       0.94      0.97      0.96       141\n            Tomato___Tomato_Yellow_Leaf_Curl_Virus       0.99      0.99      0.99       537\n                      Tomato___Tomato_mosaic_virus       0.90      0.97      0.94        38\n                                  Tomato___healthy       0.99      0.99      0.99       160\n\n                                          accuracy                           0.96      5459\n                                         macro avg       0.96      0.94      0.95      5459\n                                      weighted avg       0.97      0.96      0.96      5459\n\n","output_type":"stream"}],"execution_count":11}]}